{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr40IbZwjQSv",
        "outputId": "b4760541-ef5b-463b-9a40-026ae43a5180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May 17 20:49:30 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5mqUgm7MkvY",
        "outputId": "904c9ec2-9f2a-47af-d568-e256f3db131d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_uyfMaeyOtY",
        "outputId": "04fd4075-96be-46a3-cba2-f1b47dbf86ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-168-gec2b853 Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 23.3/78.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -r requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdpfRYRTLVPx",
        "outputId": "8f014ee5-09f3-4657-eb49-95fbb04fbddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2023-05-17 20:49:57--  https://docs.google.com/uc?export=download&confirm=t&id=1OYwrlRti4cieuvVr8ERaJhTQdFJXWT4I\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.96.101, 108.177.96.138, 108.177.96.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.96.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0g-ag-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/0fl986reo20qnhrt0cuqvge66fipgv9r/1684356525000/04309230031174164349/*/1OYwrlRti4cieuvVr8ERaJhTQdFJXWT4I?e=download&uuid=7285ca2d-1fca-4285-91b2-3e0cd0803cbd [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-05-17 20:49:57--  https://doc-0g-ag-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/0fl986reo20qnhrt0cuqvge66fipgv9r/1684356525000/04309230031174164349/*/1OYwrlRti4cieuvVr8ERaJhTQdFJXWT4I?e=download&uuid=7285ca2d-1fca-4285-91b2-3e0cd0803cbd\n",
            "Resolving doc-0g-ag-docs.googleusercontent.com (doc-0g-ag-docs.googleusercontent.com)... 108.177.126.132, 2a00:1450:4013:c01::84\n",
            "Connecting to doc-0g-ag-docs.googleusercontent.com (doc-0g-ag-docs.googleusercontent.com)|108.177.126.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 281286885 (268M) [application/x-zip]\n",
            "Saving to: ‘best.pt’\n",
            "\n",
            "best.pt             100%[===================>] 268.26M   168MB/s    in 1.6s    \n",
            "\n",
            "2023-05-17 20:49:59 (168 MB/s) - ‘best.pt’ saved [281286885/281286885]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1OYwrlRti4cieuvVr8ERaJhTQdFJXWT4I' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1OYwrlRti4cieuvVr8ERaJhTQdFJXWT4I\" -O best.pt && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3MuzGiGAlLOH"
      },
      "outputs": [],
      "source": [
        "# optional weights\n",
        "#!gdown --id 16bfiRmt9CORWLqdOFZw7uLzchGGjSmKn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VMkxmV60AMVR"
      },
      "outputs": [],
      "source": [
        "WEIGHTS_PATH = \"/content/best.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Rs1BDwkZ8VLj"
      },
      "outputs": [],
      "source": [
        "from typing import Generator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "\n",
        "def generate_frames(video_file: str) -> Generator[np.ndarray, None, None]:\n",
        "    video = cv2.VideoCapture(video_file)\n",
        "\n",
        "    while video.isOpened():\n",
        "        success, frame = video.read()\n",
        "\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        yield frame\n",
        "\n",
        "    video.release()\n",
        "\n",
        "\n",
        "def plot_image(image: np.ndarray, size: int = 12) -> None:\n",
        "    plt.figure(figsize=(size, size))\n",
        "    plt.imshow(image[...,::-1])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1zx2sjBlVAR",
        "outputId": "9ac1f021-a87c-4e82-e1ea-7dd473e9927e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 🚀 v7.0-168-gec2b853 Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m /usr/local/lib/python3.10/dist-packages/requirements.txt not found, check failed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fusing layers... \n",
            "Model summary: 416 layers, 139999708 parameters, 0 gradients, 207.9 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', WEIGHTS_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "T-MBsbRTnRwE"
      },
      "outputs": [],
      "source": [
        "# if you are using optional weights you need to run this.\n",
        "#model.names = {0: 'ball', 1: 'goalkeeper', 2: 'player', 3: 'referee'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tiOHf9_Awzj",
        "outputId": "593997c4-c32d-4b88-aace-7d972a0f8c39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'ByteTrack'...\n",
            "remote: Enumerating objects: 2007, done.\u001b[K\n",
            "remote: Total 2007 (delta 0), reused 0 (delta 0), pack-reused 2007\u001b[K\n",
            "Receiving objects: 100% (2007/2007), 79.60 MiB | 23.88 MiB/s, done.\n",
            "Resolving deltas: 100% (1141/1141), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.0.0+cu118)\n",
            "Requirement already satisfied: opencv_python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.7.0.72)\n",
            "Collecting loguru (from -r requirements.txt (line 5))\n",
            "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m247.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.19.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.65.0)\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.15.1+cu118)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (8.4.0)\n",
            "Requirement already satisfied: thop in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.1.1.post2209072238)\n",
            "Collecting ninja (from -r requirements.txt (line 11))\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.8.10)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (2.12.2)\n",
            "Collecting lap (from -r requirements.txt (line 14))\n",
            "  Downloading lap-0.4.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting motmetrics (from -r requirements.txt (line 15))\n",
            "  Downloading motmetrics-1.4.0-py3-none-any.whl (161 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.5/161.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filterpy (from -r requirements.txt (line 16))\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (3.8.0)\n",
            "Collecting onnx==1.8.1 (from -r requirements.txt (line 20))\n",
            "  Downloading onnx-1.8.1.tar.gz (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement onnxruntime==1.8.0 (from versions: 1.12.0, 1.12.1, 1.13.1, 1.14.0, 1.14.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for onnxruntime==1.8.0\u001b[0m\u001b[31m\n",
            "\u001b[0mrunning develop\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  easy_install.initialize_options(self)\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running egg_info\n",
            "creating yolox.egg-info\n",
            "writing yolox.egg-info/PKG-INFO\n",
            "writing dependency_links to yolox.egg-info/dependency_links.txt\n",
            "writing top-level names to yolox.egg-info/top_level.txt\n",
            "writing manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "building 'yolox._C' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/content\n",
            "creating build/temp.linux-x86_64-cpython-310/content/ByteTrack\n",
            "creating build/temp.linux-x86_64-cpython-310/content/ByteTrack/yolox\n",
            "creating build/temp.linux-x86_64-cpython-310/content/ByteTrack/yolox/layers\n",
            "creating build/temp.linux-x86_64-cpython-310/content/ByteTrack/yolox/layers/csrc\n",
            "creating build/temp.linux-x86_64-cpython-310/content/ByteTrack/yolox/layers/csrc/cocoeval\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/ByteTrack/yolox/layers/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/include/python3.10 -c /content/ByteTrack/yolox/layers/csrc/cocoeval/cocoeval.cpp -o build/temp.linux-x86_64-cpython-310/content/ByteTrack/yolox/layers/csrc/cocoeval/cocoeval.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/ByteTrack/yolox/layers/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/include/python3.10 -c /content/ByteTrack/yolox/layers/csrc/vision.cpp -o build/temp.linux-x86_64-cpython-310/content/ByteTrack/yolox/layers/csrc/vision.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/yolox\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/content/ByteTrack/yolox/layers/csrc/cocoeval/cocoeval.o build/temp.linux-x86_64-cpython-310/content/ByteTrack/yolox/layers/csrc/vision.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-310/yolox/_C.cpython-310-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-cpython-310/yolox/_C.cpython-310-x86_64-linux-gnu.so -> yolox\n",
            "Creating /usr/local/lib/python3.10/dist-packages/yolox.egg-link (link to .)\n",
            "Adding yolox 0.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /content/ByteTrack\n",
            "Processing dependencies for yolox==0.1.0\n",
            "Finished processing dependencies for yolox==0.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cython_bbox\n",
            "  Downloading cython_bbox-0.1.3.tar.gz (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: cython_bbox\n",
            "  Building wheel for cython_bbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cython_bbox: filename=cython_bbox-0.1.3-cp310-cp310-linux_x86_64.whl size=66956 sha256=55420ad76035a1b5f352cc88179d53481a6c408651f1d98e0624414b5b7f3869\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/f2/fc/4a4b0f3870075d64eb15a38c9ecb3c3d582677ee5f2f2e8939\n",
            "Successfully built cython_bbox\n",
            "Installing collected packages: cython_bbox\n",
            "Successfully installed cython_bbox-0.1.3\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "!cd ByteTrack && pip3 install -r requirements.txt\n",
        "!cd ByteTrack && python3 setup.py develop\n",
        "!pip install cython_bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pEIUi5qpEMeN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(f\"{HOME}/ByteTrack\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg8EL1ihJ-ay",
        "outputId": "2b84ffc7-b95b-4a12-cce9-96445067857a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/49.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install onemetric --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "07HKQl6JH21E"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.3\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av_LoNu9fZVw",
        "outputId": "53d6a56d-8695-48fb-ae47-92d68120308f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting loguru\n",
            "  Using cached loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "Installing collected packages: loguru\n",
            "Successfully installed loguru-0.7.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lap\n",
            "  Using cached lap-0.4.0.tar.gz (1.5 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: lap\n",
            "  Building wheel for lap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lap: filename=lap-0.4.0-cp310-cp310-linux_x86_64.whl size=1655221 sha256=2cb847b9af6b5302b256fb2e32af8b1a3321e5ba15ec9b66035e7ed57a842d5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/42/2e/9dfe19270eea279d79e84767ff0d7b8082c3bf776cad00e83d\n",
            "Successfully built lap\n",
            "Installing collected packages: lap\n",
            "Successfully installed lap-0.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: thop in /usr/local/lib/python3.10/dist-packages (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->thop) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->thop) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->thop) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->thop) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->thop) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install loguru\n",
        "!pip install lap\n",
        "!pip install thop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PoLrnI-DCGP",
        "outputId": "f5520b95-68b5-498c-e53c-9022f49defdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: onemetric in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from onemetric) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onemetric) (1.22.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from onemetric) (0.12.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from onemetric) (3.7.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from onemetric) (0.5.7)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->onemetric) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->onemetric) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->onemetric) (0.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->onemetric) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->onemetric) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->onemetric) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->onemetric) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->onemetric) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->onemetric) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->onemetric) (2.8.2)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn->onemetric) (1.5.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn->onemetric) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->onemetric) (1.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json->onemetric) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json->onemetric) (4.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install onemetric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "c2rMgGK8KS5D"
      },
      "outputs": [],
      "source": [
        "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "from onemetric.cv.utils.iou import box_iou_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "EBcLq7VSEJPx"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Tuple, Optional, List, Dict, Any\n",
        "\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# geometry utilities\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Point:\n",
        "    x: float\n",
        "    y: float\n",
        "    \n",
        "    @property\n",
        "    def int_xy_tuple(self) -> Tuple[int, int]:\n",
        "        return int(self.x), int(self.y)\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Rect:\n",
        "    x: float\n",
        "    y: float\n",
        "    width: float\n",
        "    height: float\n",
        "\n",
        "    @property\n",
        "    def min_x(self) -> float:\n",
        "        return self.x\n",
        "    \n",
        "    @property\n",
        "    def min_y(self) -> float:\n",
        "        return self.y\n",
        "    \n",
        "    @property\n",
        "    def max_x(self) -> float:\n",
        "        return self.x + self.width\n",
        "    \n",
        "    @property\n",
        "    def max_y(self) -> float:\n",
        "        return self.y + self.height\n",
        "        \n",
        "    @property\n",
        "    def top_left(self) -> Point:\n",
        "        return Point(x=self.x, y=self.y)\n",
        "    \n",
        "    @property\n",
        "    def bottom_right(self) -> Point:\n",
        "        return Point(x=self.x + self.width, y=self.y + self.height)\n",
        "\n",
        "    @property\n",
        "    def bottom_center(self) -> Point:\n",
        "        return Point(x=self.x + self.width / 2, y=self.y + self.height)\n",
        "\n",
        "    @property\n",
        "    def top_center(self) -> Point:\n",
        "        return Point(x=self.x + self.width / 2, y=self.y)\n",
        "\n",
        "    @property\n",
        "    def center(self) -> Point:\n",
        "        return Point(x=self.x + self.width / 2, y=self.y + self.height / 2)\n",
        "\n",
        "    def pad(self, padding: float) -> Rect:\n",
        "        return Rect(\n",
        "            x=self.x - padding, \n",
        "            y=self.y - padding,\n",
        "            width=self.width + 2*padding,\n",
        "            height=self.height + 2*padding\n",
        "        )\n",
        "    \n",
        "    def contains_point(self, point: Point) -> bool:\n",
        "        return self.min_x < point.x < self.max_x and self.min_y < point.y < self.max_y\n",
        "\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Detection:\n",
        "    rect: Rect\n",
        "    class_id: int\n",
        "    class_name: str\n",
        "    confidence: float\n",
        "    tracker_id: Optional[int] = None\n",
        "\n",
        "    @classmethod\n",
        "    def from_results(cls, pred: np.ndarray, names: Dict[int, str]) -> List[Detection]:\n",
        "        result = []\n",
        "        for x_min, y_min, x_max, y_max, confidence, class_id in pred:\n",
        "            class_id=int(class_id)\n",
        "            result.append(Detection(\n",
        "                rect=Rect(\n",
        "                    x=float(x_min),\n",
        "                    y=float(y_min),\n",
        "                    width=float(x_max - x_min),\n",
        "                    height=float(y_max - y_min)\n",
        "                ),\n",
        "                class_id=class_id,\n",
        "                class_name=names[class_id],\n",
        "                confidence=float(confidence)\n",
        "            ))\n",
        "        return result\n",
        "\n",
        "\n",
        "def filter_detections_by_class(detections: List[Detection], class_name: str) -> List[Detection]:\n",
        "    return [\n",
        "        detection\n",
        "        for detection \n",
        "        in detections\n",
        "        if detection.class_name == class_name\n",
        "    ]\n",
        "\n",
        "\n",
        "# draw utilities\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Color:\n",
        "    r: int\n",
        "    g: int\n",
        "    b: int\n",
        "        \n",
        "    @property\n",
        "    def bgr_tuple(self) -> Tuple[int, int, int]:\n",
        "        return self.b, self.g, self.r\n",
        "\n",
        "    @classmethod\n",
        "    def from_hex_string(cls, hex_string: str) -> Color:\n",
        "        r, g, b = tuple(int(hex_string[1 + i:1 + i + 2], 16) for i in (0, 2, 4))\n",
        "        return Color(r=r, g=g, b=b)\n",
        "\n",
        "\n",
        "def draw_rect(image: np.ndarray, rect: Rect, color: Color, thickness: int = 2) -> np.ndarray:\n",
        "    cv2.rectangle(image, rect.top_left.int_xy_tuple, rect.bottom_right.int_xy_tuple, color.bgr_tuple, thickness)\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_filled_rect(image: np.ndarray, rect: Rect, color: Color) -> np.ndarray:\n",
        "    cv2.rectangle(image, rect.top_left.int_xy_tuple, rect.bottom_right.int_xy_tuple, color.bgr_tuple, -1)\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_polygon(image: np.ndarray, countour: np.ndarray, color: Color, thickness: int = 2) -> np.ndarray:\n",
        "    cv2.drawContours(image, [countour], 0, color.bgr_tuple, thickness)\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_filled_polygon(image: np.ndarray, countour: np.ndarray, color: Color) -> np.ndarray:\n",
        "    cv2.drawContours(image, [countour], 0, color.bgr_tuple, -1)\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_text(image: np.ndarray, anchor: Point, text1: str, text2: str, color: Color, thickness: int = 2) -> np.ndarray:\n",
        "    new_tuple = (anchor.int_xy_tuple[0], anchor.int_xy_tuple[1] - 90)\n",
        "\n",
        "    cv2.putText(image, text1, new_tuple, cv2.FONT_HERSHEY_SIMPLEX, 0.7, color.bgr_tuple, thickness, 2, False)\n",
        "    cv2.putText(image, text2, anchor.int_xy_tuple, cv2.FONT_HERSHEY_SIMPLEX, 0.7, color.bgr_tuple, thickness, 2, False)\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_ellipse(image: np.ndarray, rect: Rect, color: Color, thickness: int = 2) -> np.ndarray:\n",
        "    cv2.ellipse(\n",
        "        image,\n",
        "        center=rect.bottom_center.int_xy_tuple,\n",
        "        axes=(int(rect.width), int(0.35 * rect.width)),\n",
        "        angle=0.0,\n",
        "        startAngle=-45,\n",
        "        endAngle=235,\n",
        "        color=color.bgr_tuple,\n",
        "        thickness=thickness,\n",
        "        lineType=cv2.LINE_4\n",
        "    )\n",
        "    return image\n",
        "\n",
        "\n",
        "# base annotator\n",
        "  \n",
        "\n",
        "@dataclass\n",
        "class BaseAnnotator:\n",
        "    colors: List[Color]\n",
        "    thickness: int\n",
        "\n",
        "    def annotate(self, image: np.ndarray, detections: List[Detection]) -> np.ndarray:\n",
        "        annotated_image = image.copy()\n",
        "        for detection in detections:\n",
        "            annotated_image = draw_ellipse(\n",
        "                image=image,\n",
        "                rect=detection.rect,\n",
        "                color=self.colors[detection.class_id],\n",
        "                thickness=self.thickness\n",
        "            )\n",
        "        return annotated_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KvoYej_INhAB"
      },
      "outputs": [],
      "source": [
        "# white\n",
        "BALL_COLOR_HEX = \"#FFFFFF\"\n",
        "BALL_COLOR = Color.from_hex_string(BALL_COLOR_HEX)\n",
        "\n",
        "# red\n",
        "GOALKEEPER_COLOR_HEX = \"#850101\"\n",
        "GOALKEEPER_COLOR = Color.from_hex_string(GOALKEEPER_COLOR_HEX)\n",
        "\n",
        "# green\n",
        "PLAYER_COLOR_HEX = \"#00D4BB\"\n",
        "PLAYER_COLOR = Color.from_hex_string(PLAYER_COLOR_HEX)\n",
        "\n",
        "# yellow\n",
        "REFEREE_COLOR_HEX = \"#FFFF00\"\n",
        "REFEREE_COLOR = Color.from_hex_string(REFEREE_COLOR_HEX)\n",
        "\n",
        "COLORS = [\n",
        "    BALL_COLOR,\n",
        "    GOALKEEPER_COLOR,\n",
        "    PLAYER_COLOR,\n",
        "    REFEREE_COLOR\n",
        "]\n",
        "THICKNESS = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-J7lHOwWAvia"
      },
      "outputs": [],
      "source": [
        "# black\n",
        "MARKER_CONTOUR_COLOR_HEX = \"000000\"\n",
        "MARKER_CONTOUR_COLOR = Color.from_hex_string(MARKER_CONTOUR_COLOR_HEX)\n",
        "\n",
        "# red\n",
        "PLAYER_MARKER_FILL_COLOR_HEX = \"FF0000\"\n",
        "PLAYER_MARKER_FILL_COLOR = Color.from_hex_string(PLAYER_MARKER_FILL_COLOR_HEX)\n",
        "\n",
        "# green\n",
        "BALL_MERKER_FILL_COLOR_HEX = \"00FF00\"\n",
        "BALL_MARKER_FILL_COLOR = Color.from_hex_string(BALL_MERKER_FILL_COLOR_HEX)\n",
        "\n",
        "MARKER_CONTOUR_THICKNESS = 2\n",
        "MARKER_WIDTH = 20\n",
        "MARKER_HEIGHT = 20\n",
        "MARKER_MARGIN = 10\n",
        "\n",
        "# distance in pixels from the player's bounding box where we consider the ball is in his possession\n",
        "PLAYER_IN_POSSESSION_PROXIMITY = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "JH5AkurLCDO7"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# calculates coordinates of possession marker\n",
        "def calculate_marker(anchor: Point) -> np.ndarray:\n",
        "    x, y = anchor.int_xy_tuple\n",
        "    return(np.array([\n",
        "        [x - MARKER_WIDTH // 2, y - MARKER_HEIGHT - MARKER_MARGIN],\n",
        "        [x, y - MARKER_MARGIN],\n",
        "        [x + MARKER_WIDTH // 2, y - MARKER_HEIGHT - MARKER_MARGIN]\n",
        "    ]))\n",
        "\n",
        "\n",
        "# draw single possession marker\n",
        "def draw_marker(image: np.ndarray, anchor: Point, color: Color) -> np.ndarray:\n",
        "    possession_marker_countour = calculate_marker(anchor=anchor)\n",
        "    image = draw_filled_polygon(\n",
        "        image=image, \n",
        "        countour=possession_marker_countour, \n",
        "        color=color)\n",
        "    image = draw_polygon(\n",
        "        image=image, \n",
        "        countour=possession_marker_countour, \n",
        "        color=MARKER_CONTOUR_COLOR,\n",
        "        thickness=MARKER_CONTOUR_THICKNESS)\n",
        "    return image\n",
        "\n",
        "\n",
        "# dedicated annotator to draw possession markers on video frames\n",
        "@dataclass\n",
        "class MarkerAnntator:\n",
        "\n",
        "    color: Color\n",
        "\n",
        "    def annotate(self, image: np.ndarray, detections: List[Detection]) -> np.ndarray:\n",
        "        annotated_image = image.copy()\n",
        "        for detection in detections:\n",
        "            annotated_image = draw_marker(\n",
        "                image=image, \n",
        "                anchor=detection.rect.top_center,\n",
        "                color=self.color)\n",
        "        return annotated_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "28XZOT4eHqhd"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "\n",
        "# resolves which player is currently in ball possession based on player-ball proximity\n",
        "def get_player_in_possession(\n",
        "    player_detections: List[Detection], \n",
        "    ball_detections: List[Detection],\n",
        "    proximity: int\n",
        ") -> Optional[Detection]:\n",
        "    if len(ball_detections) != 1:\n",
        "        return None\n",
        "    ball_detection = ball_detections[0]\n",
        "\n",
        "    for player_detection in player_detections:\n",
        "        if player_detection.rect.pad(proximity).contains_point(point=ball_detection.rect.center):\n",
        "            return player_detection\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "0ZordbZHZqIh"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "import cv2\n",
        "\n",
        "\n",
        "\n",
        "# stores information about output video file, width and height of the frame must be equal to input video\n",
        "@dataclass(frozen=True)\n",
        "class VideoConfig:\n",
        "    fps: float\n",
        "    width: int\n",
        "    height: int\n",
        "        \n",
        "\n",
        "# create cv2.VideoWriter object that we can use to save output video\n",
        "def get_video_writer(target_video_path: str, video_config: VideoConfig) -> cv2.VideoWriter:\n",
        "    video_target_dir = os.path.dirname(os.path.abspath(target_video_path))\n",
        "    os.makedirs(video_target_dir, exist_ok=True)\n",
        "    return cv2.VideoWriter(\n",
        "        target_video_path, \n",
        "        fourcc=cv2.VideoWriter_fourcc(*\"mp4v\"), \n",
        "        fps=video_config.fps, \n",
        "        frameSize=(video_config.width, video_config.height), \n",
        "        isColor=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "7wFkxJQrXokI"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# converts List[Detection] into format that can be consumed by match_detections_with_tracks function\n",
        "def detections2boxes(detections: List[Detection], with_confidence: bool = True) -> np.ndarray:\n",
        "    return np.array([\n",
        "        [\n",
        "            detection.rect.top_left.x, \n",
        "            detection.rect.top_left.y,\n",
        "            detection.rect.bottom_right.x,\n",
        "            detection.rect.bottom_right.y,\n",
        "            detection.confidence\n",
        "        ] if with_confidence else [\n",
        "            detection.rect.top_left.x, \n",
        "            detection.rect.top_left.y,\n",
        "            detection.rect.bottom_right.x,\n",
        "            detection.rect.bottom_right.y\n",
        "        ]\n",
        "        for detection\n",
        "        in detections\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
        "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
        "    return np.array([\n",
        "        track.tlbr\n",
        "        for track\n",
        "        in tracks\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# matches our bounding boxes with predictions\n",
        "def match_detections_with_tracks(\n",
        "    detections: List[Detection], \n",
        "    tracks: List[STrack]\n",
        ") -> List[Detection]:\n",
        "    detection_boxes = detections2boxes(detections=detections, with_confidence=False)\n",
        "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
        "    iou = box_iou_batch(tracks_boxes, detection_boxes)\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "  \n",
        "  \n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            detections[detection_index].tracker_id = tracks[tracker_index].track_id\n",
        "    return detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Hmqn7yL81KLH"
      },
      "outputs": [],
      "source": [
        "stamina_threshold = 1000\n",
        "stamina_distance_threshold = 3\n",
        "stamina_values = {}\n",
        "ball_values = {}\n",
        "@dataclass\n",
        "class TextAnnotator:\n",
        "    background_color: Color\n",
        "    text_color: Color\n",
        "    text_thickness: int\n",
        "\n",
        "\n",
        "    def annotate(self, image: np.ndarray, detections: List[Detection], distance: Dict, frame_count: int, ball_dict: List, all_ids: List, df: pd.DataFrame) -> np.ndarray:\n",
        "        annotated_image = image.copy()\n",
        "        distance_list = []\n",
        "        ball_list = []\n",
        "        if frame_count == 1:\n",
        "            stamina_performance = 100\n",
        "            ball_performance = 100\n",
        "        \n",
        "        for detection in detections:\n",
        "            # if tracker_id is not assigned skip annotation\n",
        "\n",
        "            if detection.tracker_id == None:\n",
        "                continue\n",
        "            if detection.tracker_id in distance.keys():\n",
        "                stamina_list = distance[detection.tracker_id]\n",
        "            else:\n",
        "              continue\n",
        "\n",
        "            if frame_count != 1:\n",
        "                if detection.tracker_id in stamina_values.keys():\n",
        "                    stamina_performance = stamina_values[detection.tracker_id]\n",
        "                else:\n",
        "                    stamina_performance = 100\n",
        "                \n",
        "                if detection.tracker_id in ball_values.keys():\n",
        "                    ball_performance = ball_values[detection.tracker_id]\n",
        "                else:\n",
        "                    ball_performance = 100\n",
        "\n",
        "            prev_stamina = None\n",
        "            stamina_counter = 0\n",
        "\n",
        "            if frame_count < stamina_threshold:\n",
        "                stamina = stamina_list[0]\n",
        "            else:\n",
        "                stamina_index = (frame_count // stamina_threshold) \n",
        "                stamina = stamina_list[stamina_index]\n",
        "                if prev_stamina is not None and stamina < prev_stamina:\n",
        "                    stamina_counter += 1\n",
        "                    if stamina_counter == stamina_distance_threshold:\n",
        "                        stamina_performance -= 1\n",
        "                        stamina_counter = 0\n",
        "                else:\n",
        "                    stamina_counter = 0\n",
        "                prev_stamina = stamina\n",
        "\n",
        "                        \n",
        "            if detection.tracker_id == None:\n",
        "                continue\n",
        "\n",
        "            if frame_count < stamina_threshold:\n",
        "                d = ball_dict[0]\n",
        "            else:\n",
        "                ball_index = (frame_count // stamina_threshold) - 1\n",
        "                d = ball_dict[ball_index]\n",
        "            \n",
        "            sorted_items = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
        "            top = sorted_items[1]\n",
        "            \n",
        "            top_key = top[1]\n",
        "            \n",
        "            if frame_count % stamina_threshold == 0:\n",
        "                if detection.tracker_id == top_key:\n",
        "                    ball_performance = ball_performance - 1\n",
        "\n",
        "\n",
        "            stamina_values[detection.tracker_id] = stamina_performance\n",
        "\n",
        "            ball_values[detection.tracker_id] = ball_performance\n",
        "           \n",
        "\n",
        "            stamina_percent = stamina_performance * 0.4 + ball_performance * 0.6\n",
        "\n",
        "            \n",
        "            \n",
        "            row_dict = {}\n",
        "            # Loop through each id\n",
        "            for id in all_ids:\n",
        "              if id == detection.tracker_id:\n",
        "                row_dict[id] = stamina_percent\n",
        "              else:\n",
        "                continue\n",
        "            first_key, first_value = next(iter(row_dict.items()))\n",
        "            df.loc[frame_count, first_key] = first_value\n",
        "\n",
        "\n",
        "                    \n",
        "                  \n",
        "            # calculate text dimensions\n",
        "            size, _ = cv2.getTextSize(\n",
        "                str(detection.tracker_id), \n",
        "                cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                0.7, \n",
        "                thickness=self.text_thickness)\n",
        "            width, height = size\n",
        "            \n",
        "            # calculate text background position\n",
        "            center_x, center_y = detection.rect.bottom_center.int_xy_tuple\n",
        "            x = center_x - width // 2\n",
        "            y = center_y - height // 2 + 10\n",
        "            \n",
        "            # draw background\n",
        "            annotated_image = draw_filled_rect(\n",
        "                image=annotated_image, \n",
        "                rect=Rect(x=x, y=y, width=width, height=height).pad(padding=5), \n",
        "                color=self.background_color)\n",
        "            \n",
        "            # draw text\n",
        "            annotated_image = draw_text(\n",
        "                image=annotated_image, \n",
        "                anchor=Point(x=x, y=y + height), \n",
        "                text2=str(stamina_percent),\n",
        "                text1=str(detection.tracker_id),\n",
        "                color=self.text_color, \n",
        "                thickness=self.text_thickness)\n",
        "        # if df['Unnamed: 0'] == True:\n",
        "        #   df = df.drop('Unnamed: 0', axis=1)\n",
        "        df.to_csv('detection.csv')\n",
        "        return annotated_image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7mhFb91Of2oO"
      },
      "outputs": [],
      "source": [
        "ball_marker_annotator = MarkerAnntator(color=BALL_MARKER_FILL_COLOR)\n",
        "player_marker_annotator = MarkerAnntator(color=PLAYER_MARKER_FILL_COLOR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl5bDvf5G2V1",
        "outputId": "f4f6a41a-6d1d-4481-9ebe-aa92b48ea7a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZuBwc2Cm7y4UzZWHE4rZnaVz1qtx2fjg\n",
            "To: /content/sample_check.mp4\n",
            "100% 323M/323M [00:01<00:00, 234MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1ZuBwc2Cm7y4UzZWHE4rZnaVz1qtx2fjg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "jYM4lks7VzOX"
      },
      "outputs": [],
      "source": [
        "# settings\n",
        "# SOURCE_VIDEO_PATH = f\"{HOME}/match.mp4\"\n",
        "# TARGET_VIDEO_PATH = f\"{HOME}/final/0a2d9b_0.mp4\"\n",
        "\n",
        "SOURCE_VIDEO_PATH = '/content/sample_check.mp4'\n",
        "TARGET_VIDEO_PATH = f\"{HOME}/final/08fd33_4.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "xuPZlRDvlCiZ"
      },
      "outputs": [],
      "source": [
        "def distance_sum(id):\n",
        "\n",
        "  i = 1\n",
        "  distance_list = []\n",
        "  player = []\n",
        "\n",
        "  for frame in stamina_detection:\n",
        "    for detection in frame:\n",
        "      if detection.tracker_id == id:\n",
        "        player.append(detection)\n",
        "\n",
        "    if len(player) == 0:  # Add a check to ensure player list is not empty\n",
        "      continue\n",
        "\n",
        "    x1 = player[0].rect.x\n",
        "    y1 = player[0].rect.y\n",
        "\n",
        "    total_x = 0\n",
        "    total_y = 0\n",
        "\n",
        "    for frame in player[1:]:\n",
        "      \n",
        "      x = frame.rect.x\n",
        "      y = frame.rect.y\n",
        "\n",
        "      diff_x = abs(x - x1)\n",
        "\n",
        "      diff_y = abs(y - y1)\n",
        "\n",
        "      x1 = x\n",
        "      y1 = y\n",
        "\n",
        "      total_x = total_x + diff_x \n",
        "      total_y = total_y + diff_y \n",
        "\n",
        "    distance = round(total_x + total_y, 2)\n",
        "\n",
        "    if i % stamina_threshold == 0:\n",
        "      distance_list.append(distance)\n",
        "\n",
        "    i = i + 1\n",
        "\n",
        "  return distance_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1bJzrpP-mcJQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "38cb88a8043a4455a44471e03f84c836",
            "5a7c8e5be15940fdbe9dc2c9c4abc4c9",
            "6ea2db16cbee4b2b9401f118ea0d2fc6",
            "0e341e554b5a480ab2a23296cfd3687e",
            "b987c45cb31344fe8b0618cbf66eb465",
            "5d07ca038602411287566e61fd2acfca",
            "752672c9054146c0b9a855a236b86506",
            "58f61ef10b2e4196856fc58ba3cae4c6",
            "59023ee8b8494718975500ac58251614",
            "e9886880da0641f89e0af3548a789bde",
            "18a6d6c0b89d4fe38cc1f23e287d654b"
          ]
        },
        "id": "SELyRdNDIsS-",
        "outputId": "7a5b3285-a558-4aad-b525-bb42d87194b0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/7000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38cb88a8043a4455a44471e03f84c836"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "stamina_detection = []\n",
        "ball_possestion = []\n",
        "ball_pos = []\n",
        "tracked_detections_list = []\n",
        "tracked_keeper_player_list= []\n",
        "tracked_referee_detections_list = []\n",
        "ball_detections_list = []\n",
        "empty_dict = {}\n",
        "empty_list = []\n",
        "df_empty = pd.DataFrame()\n",
        "player_in_possession_detection_list = []\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "# initiate video writer\n",
        "video_config = VideoConfig(\n",
        "    fps=30, \n",
        "    width=1920, \n",
        "    height=1080)\n",
        "video_writer = get_video_writer(\n",
        "    target_video_path=TARGET_VIDEO_PATH, \n",
        "    video_config=video_config)\n",
        "\n",
        "# get fresh video frame generator\n",
        "frame_iterator = iter(generate_frames(video_file=SOURCE_VIDEO_PATH))\n",
        "\n",
        "# initiate annotators\n",
        "base_annotator = BaseAnnotator(\n",
        "    colors=[\n",
        "        BALL_COLOR,\n",
        "        PLAYER_COLOR,\n",
        "        PLAYER_COLOR,\n",
        "        REFEREE_COLOR\n",
        "    ], \n",
        "    thickness=THICKNESS)\n",
        "\n",
        "player_goalkeeper_text_annotator = TextAnnotator(\n",
        "    PLAYER_COLOR, text_color=Color(255, 255, 255), text_thickness=2)\n",
        "referee_text_annotator = TextAnnotator(\n",
        "    REFEREE_COLOR, text_color=Color(0, 0, 0), text_thickness=2)\n",
        "\n",
        "ball_marker_annotator = MarkerAnntator(\n",
        "    color=BALL_MARKER_FILL_COLOR)\n",
        "player_in_possession_marker_annotator = MarkerAnntator(\n",
        "    color=PLAYER_MARKER_FILL_COLOR)\n",
        "\n",
        "\n",
        "# initiate tracker\n",
        "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
        "\n",
        "total_frames = 0\n",
        "\n",
        "\n",
        "# loop over frames\n",
        "for frame in tqdm(frame_iterator, total=7000):\n",
        "\n",
        "    total_frames = total_frames + 1\n",
        "    # run detector\n",
        "    results = model(frame, size=1920)\n",
        "    detections = Detection.from_results(\n",
        "        pred=results.pred[0].cpu().numpy(), \n",
        "        names=model.names)\n",
        "    \n",
        "    # filter detections by class\n",
        "    ball_detections = filter_detections_by_class(detections=detections, class_name=\"ball\")\n",
        "    referee_detections = filter_detections_by_class(detections=detections, class_name=\"referee\")\n",
        "    goalkeeper_detections = filter_detections_by_class(detections=detections, class_name=\"goalkeeper\")\n",
        "    player_detections = filter_detections_by_class(detections=detections, class_name=\"player\")\n",
        "    \n",
        "    player_goalkeeper_detections = player_detections + goalkeeper_detections\n",
        "    tracked_detections = player_detections + goalkeeper_detections + referee_detections\n",
        "\n",
        "    \n",
        "\n",
        "    # calculate player in possession\n",
        "    \n",
        "    \n",
        "    \n",
        "    # track\n",
        "    tracks = byte_tracker.update(\n",
        "        output_results=detections2boxes(detections=tracked_detections),\n",
        "        img_info=frame.shape,\n",
        "        img_size=frame.shape\n",
        "    )\n",
        "    tracked_detections = match_detections_with_tracks(detections=tracked_detections, tracks=tracks)\n",
        "\n",
        "    tracked_referee_detections = filter_detections_by_class(detections=tracked_detections, class_name=\"referee\")\n",
        "    tracked_goalkeeper_detections = filter_detections_by_class(detections=tracked_detections, class_name=\"goalkeeper\")\n",
        "    tracked_player_detections = filter_detections_by_class(detections=tracked_detections, class_name=\"player\")\n",
        "\n",
        "    stamina_detection.append(tracked_player_detections)\n",
        "\n",
        "\n",
        "    player_in_possession_detection = get_player_in_possession(\n",
        "        player_detections=tracked_player_detections,\n",
        "        ball_detections=ball_detections,\n",
        "        proximity=PLAYER_IN_POSSESSION_PROXIMITY)\n",
        "    \n",
        "    stamina_detection.append(tracked_player_detections)\n",
        "    \n",
        "    if player_in_possession_detection == None:\n",
        "      player_in_possession_detection_list.append(0)\n",
        "    else:\n",
        "      player_in_possession_detection_list.append(player_in_possession_detection)\n",
        "\n",
        "\n",
        "    ball_possestion.append(player_in_possession_detection)\n",
        "    if total_frames % stamina_threshold == 0:\n",
        "      ball_pos.append(ball_possestion)\n",
        "      ball_possestion = []\n",
        "\n",
        "    tracked_detections_list.append(tracked_detections)\n",
        "\n",
        "    tracked_keeper_player_list.append(tracked_goalkeeper_detections + tracked_player_detections)\n",
        "\n",
        "    tracked_referee_detections_list.append(tracked_referee_detections)\n",
        "\n",
        "    ball_detections_list.append(ball_detections)\n",
        "\n",
        "\n",
        "    # annotate video frame\n",
        "    annotated_image = frame.copy()\n",
        "    annotated_image = base_annotator.annotate(\n",
        "        image=annotated_image, \n",
        "        detections=tracked_detections)\n",
        "    \n",
        "    annotated_image = player_goalkeeper_text_annotator.annotate(\n",
        "        image=annotated_image,\n",
        "        ball_dict=empty_dict,\n",
        "        all_ids=empty_list,\n",
        "        distance=empty_dict,\n",
        "        df=df_empty,\n",
        "        frame_count = 2,\n",
        "        detections=tracked_goalkeeper_detections + tracked_player_detections)\n",
        "    annotated_image = referee_text_annotator.annotate(\n",
        "        image=annotated_image,\n",
        "        ball_dict=empty_dict,\n",
        "        all_ids=empty_list,\n",
        "        distance=empty_dict,\n",
        "        df=df_empty,\n",
        "        frame_count = 2,\n",
        "        detections=tracked_referee_detections)\n",
        "    \n",
        "    annotated_image = ball_marker_annotator.annotate(\n",
        "        image=annotated_image, \n",
        "        detections=ball_detections)\n",
        "    annotated_image = player_marker_annotator.annotate(\n",
        "        image=annotated_image, \n",
        "        detections=[player_in_possession_detection] if player_in_possession_detection else [])\n",
        "\n",
        "    # save video frame\n",
        "    video_writer.write(annotated_image)\n",
        "\n",
        "# Print the number of times each name appears\n",
        "\n",
        "\n",
        "# close output video\n",
        "video_writer.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdmdiFBs_-zq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEyWGPDhjA_f"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "ball_pos = [[value for value in sublist if value is not None] for sublist in ball_pos]\n",
        "player_count = []\n",
        "for sublist in ball_pos:\n",
        "    id_counts = {}\n",
        "    for detection in sublist:\n",
        "        if detection.tracker_id in id_counts:\n",
        "            id_counts[detection.tracker_id] += 1\n",
        "        else:\n",
        "            id_counts[detection.tracker_id] = 1\n",
        "    player_count.append(id_counts)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTFQbmaANDoH"
      },
      "outputs": [],
      "source": [
        "def calculate_increases(lst):\n",
        "    increases = [lst[0]]\n",
        "    for i in range(1, len(lst)):\n",
        "        increases.append(abs(lst[i] - lst[i-1]))\n",
        "    return increases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifIxX0JY2q7V"
      },
      "outputs": [],
      "source": [
        "all_ids = []\n",
        "distances = {}\n",
        "\n",
        "for frame in stamina_detection:\n",
        "  for detection in frame:\n",
        "      if detection.tracker_id in all_ids:\n",
        "        continue\n",
        "      else:\n",
        "          all_ids.append(detection.tracker_id)\n",
        "all_ids = [value for value in all_ids if value is not None]\n",
        "for i in all_ids:\n",
        "  \n",
        "  distances[i] = distance_sum(i)\n",
        "\n",
        "max_len = max(len(v) for v in distances.values())\n",
        "\n",
        "for v in distances.values():\n",
        "    while len(v) < max_len:\n",
        "        v.append(0)\n",
        "\n",
        "\n",
        "distances_new = {}\n",
        "\n",
        "for key, value in distances.items():\n",
        "    distances_new[key] = calculate_increases(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4oowCEyNVPg"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "empty_dict = {}\n",
        "dataframe = pd.DataFrame(columns = all_ids)\n",
        "# initiate video writer\n",
        "video_config = VideoConfig(\n",
        "    fps=30, \n",
        "    width=1920, \n",
        "    height=1080)\n",
        "video_writer = get_video_writer(\n",
        "    target_video_path=TARGET_VIDEO_PATH, \n",
        "    video_config=video_config)\n",
        "\n",
        "# get fresh video frame generator\n",
        "frame_iterator = iter(generate_frames(video_file=SOURCE_VIDEO_PATH))\n",
        "\n",
        "# initiate annotators\n",
        "base_annotator = BaseAnnotator(\n",
        "    colors=[\n",
        "        BALL_COLOR,\n",
        "        PLAYER_COLOR,\n",
        "        PLAYER_COLOR,\n",
        "        REFEREE_COLOR\n",
        "    ], \n",
        "    thickness=THICKNESS)\n",
        "\n",
        "player_goalkeeper_text_annotator = TextAnnotator(\n",
        "    PLAYER_COLOR, text_color=Color(255, 255, 255), text_thickness=2)\n",
        "referee_text_annotator = TextAnnotator(\n",
        "    REFEREE_COLOR, text_color=Color(0, 0, 0), text_thickness=2)\n",
        "\n",
        "ball_marker_annotator = MarkerAnntator(\n",
        "    color=BALL_MARKER_FILL_COLOR)\n",
        "player_in_possession_marker_annotator = MarkerAnntator(\n",
        "    color=PLAYER_MARKER_FILL_COLOR)\n",
        "\n",
        "i = 0\n",
        "\n",
        "for frame in tqdm(frame_iterator, total=7000):\n",
        "    i = i + 1\n",
        "    if i == total_frames:\n",
        "      break\n",
        "    tracked_detections = tracked_detections_list[i]\n",
        "    tracked_detections_k_p = tracked_keeper_player_list[i]\n",
        "    tracked_referee_detections = tracked_referee_detections_list[i]\n",
        "    ball_detections = ball_detections_list[i]\n",
        "    player_in_possession_detection = player_in_possession_detection_list[i]\n",
        "\n",
        "\n",
        "  # annotate video frame\n",
        "    annotated_image = frame.copy()\n",
        "    annotated_image = base_annotator.annotate(\n",
        "        image=annotated_image, \n",
        "        detections=tracked_detections)\n",
        "    \n",
        "    annotated_image = player_goalkeeper_text_annotator.annotate(\n",
        "        image=annotated_image,\n",
        "        all_ids=all_ids,\n",
        "        distance=distances_new,\n",
        "        frame_count=i,\n",
        "        df=dataframe,\n",
        "        ball_dict=player_count,\n",
        "        detections=tracked_detections_k_p)\n",
        "    annotated_image = referee_text_annotator.annotate(\n",
        "        image=annotated_image,\n",
        "        distance=empty_dict,\n",
        "        df=dataframe,\n",
        "        all_ids=all_ids,\n",
        "        frame_count=i,\n",
        "        ball_dict=player_count,\n",
        "        detections=tracked_referee_detections)\n",
        "    \n",
        "    annotated_image = ball_marker_annotator.annotate(\n",
        "        image=annotated_image,\n",
        "        detections=ball_detections)\n",
        "    annotated_image = player_marker_annotator.annotate(\n",
        "        image=annotated_image,\n",
        "        detections=[player_in_possession_detection] if player_in_possession_detection else [])\n",
        "\n",
        "    # save video frame\n",
        "    video_writer.write(annotated_image)\n",
        "\n",
        "# close output video\n",
        "video_writer.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMhtU9KEYmnI"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/final/08fd33_4.mp4') "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "38cb88a8043a4455a44471e03f84c836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a7c8e5be15940fdbe9dc2c9c4abc4c9",
              "IPY_MODEL_6ea2db16cbee4b2b9401f118ea0d2fc6",
              "IPY_MODEL_0e341e554b5a480ab2a23296cfd3687e"
            ],
            "layout": "IPY_MODEL_b987c45cb31344fe8b0618cbf66eb465"
          }
        },
        "5a7c8e5be15940fdbe9dc2c9c4abc4c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d07ca038602411287566e61fd2acfca",
            "placeholder": "​",
            "style": "IPY_MODEL_752672c9054146c0b9a855a236b86506",
            "value": "  1%"
          }
        },
        "6ea2db16cbee4b2b9401f118ea0d2fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58f61ef10b2e4196856fc58ba3cae4c6",
            "max": 7000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59023ee8b8494718975500ac58251614",
            "value": 74
          }
        },
        "0e341e554b5a480ab2a23296cfd3687e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9886880da0641f89e0af3548a789bde",
            "placeholder": "​",
            "style": "IPY_MODEL_18a6d6c0b89d4fe38cc1f23e287d654b",
            "value": " 74/7000 [00:22&lt;34:10,  3.38it/s]"
          }
        },
        "b987c45cb31344fe8b0618cbf66eb465": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d07ca038602411287566e61fd2acfca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "752672c9054146c0b9a855a236b86506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58f61ef10b2e4196856fc58ba3cae4c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59023ee8b8494718975500ac58251614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9886880da0641f89e0af3548a789bde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18a6d6c0b89d4fe38cc1f23e287d654b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}